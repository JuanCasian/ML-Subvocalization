{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to data folder\n",
    "train_data_path = \"/home/jp_capo_98/Documents/ML-Silent-Speech-Recognition/Data/train_data/images/\"\n",
    "test_data_path = \"/home/jp_capo_98/Documents/ML-Silent-Speech-Recognition/Data/test_data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train data\n",
    "train_data = {\"label\":[], \"ch1\":[], \"ch2\":[], \"ch3\":[], \"ch4\":[]}\n",
    "for folder in os.listdir(train_data_path):\n",
    "    dataset_folder = train_data_path + folder + \"/\"\n",
    "    for subdir in os.listdir(dataset_folder):\n",
    "        label = subdir\n",
    "        train_subdir = dataset_folder + subdir + \"/\"\n",
    "        ch1_subdir = train_subdir + \"ch1/\"\n",
    "        for file in os.listdir(ch1_subdir):\n",
    "            ch1_filepath = train_subdir + \"ch1/\" + file\n",
    "            ch2_filepath = train_subdir + \"ch2/\" + file\n",
    "            ch3_filepath = train_subdir + \"ch3/\" + file\n",
    "            ch4_filepath = train_subdir + \"ch4/\" + file\n",
    "            train_data[\"label\"].append(label)\n",
    "            train_data[\"ch1\"].append(ch1_filepath)\n",
    "            train_data[\"ch2\"].append(ch2_filepath)\n",
    "            train_data[\"ch3\"].append(ch3_filepath)\n",
    "            train_data[\"ch4\"].append(ch4_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch1</th>\n",
       "      <th>ch2</th>\n",
       "      <th>ch3</th>\n",
       "      <th>ch4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ch1  \\\n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "\n",
       "                                                 ch2  \\\n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "\n",
       "                                                 ch3  \\\n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "\n",
       "                                                 ch4 label  \n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   one  \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   one  \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   one  \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   one  \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   one  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df = pd.DataFrame(train_data)\n",
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test_data\n",
    "test_data = {\"filename\":[], \"ch1\":[], \"ch2\":[], \"ch3\":[], \"ch4\":[]}\n",
    "for folder in os.listdir(test_data_path):\n",
    "    filename = folder\n",
    "    test_subdir = test_data_path + folder + \"/\"\n",
    "    ch1_filepath = test_subdir + \"ch1.png\"\n",
    "    ch2_filepath = test_subdir + \"ch2.png\"\n",
    "    ch3_filepath = test_subdir + \"ch3.png\"\n",
    "    ch4_filepath = test_subdir + \"ch4.png\"\n",
    "    test_data[\"filename\"].append(filename)\n",
    "    test_data[\"ch1\"].append(ch1_filepath)\n",
    "    test_data[\"ch2\"].append(ch2_filepath)\n",
    "    test_data[\"ch3\"].append(ch3_filepath)\n",
    "    test_data[\"ch4\"].append(ch4_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch1</th>\n",
       "      <th>ch2</th>\n",
       "      <th>ch3</th>\n",
       "      <th>ch4</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>Y3K7JETF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>W6HOIV84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>UT7X0FXK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>396IEJUQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>ETWR1EHV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ch1  \\\n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "\n",
       "                                                 ch2  \\\n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "\n",
       "                                                 ch3  \\\n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "\n",
       "                                                 ch4  filename  \n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...  Y3K7JETF  \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...  W6HOIV84  \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...  UT7X0FXK  \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...  396IEJUQ  \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...  ETWR1EHV  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df = pd.DataFrame(test_data)\n",
    "test_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding dictionary\n",
    "one_hot_encoding = {\"one\":[1, 0],\n",
    "                   \"two\":[0, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot decoding dictionary for argmax\n",
    "one_hot_decoding = {0:\"one\",\n",
    "                   1:\"two\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5078eca550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show one of the train spectograms\n",
    "sample = train_data_df.sample()\n",
    "plt.imshow(skimage.io.imread(sample.ch4.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 800, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skimage.io.imread(sample.ch4.iloc[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch1</th>\n",
       "      <th>ch2</th>\n",
       "      <th>ch3</th>\n",
       "      <th>ch4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>/home/jp_capo_98/Documents/ML-Silent-Speech-Re...</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ch1  \\\n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "\n",
       "                                                 ch2  \\\n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "\n",
       "                                                 ch3  \\\n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   \n",
       "\n",
       "                                                 ch4 label  \n",
       "0  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   two  \n",
       "1  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   two  \n",
       "2  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   one  \n",
       "3  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   two  \n",
       "4  /home/jp_capo_98/Documents/ML-Silent-Speech-Re...   two  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shufle data frame to make diferent datasets\n",
    "shuffled_df = train_data_df.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5119, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean labels\n",
    "labels = np.array([one_hot_encoding[val] for val in shuffled_df.label.values])\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train_data_labels = labels[:4609]\n",
    "train_data_ch1 = shuffled_df.ch1.values[:4609]\n",
    "train_data_ch2 = shuffled_df.ch2.values[:4609]\n",
    "train_data_ch3 = shuffled_df.ch3.values[:4609]\n",
    "train_data_ch4 = shuffled_df.ch4.values[:4609]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "validation_data_labels = labels[4609:]\n",
    "validation_data_ch1 = shuffled_df.ch1.values[4609:]\n",
    "validation_data_ch2 = shuffled_df.ch2.values[4609:]\n",
    "validation_data_ch3 = shuffled_df.ch3.values[4609:]\n",
    "validation_data_ch4 = shuffled_df.ch4.values[4609:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Y3K7JETF\n",
       "1    W6HOIV84\n",
       "2    UT7X0FXK\n",
       "3    396IEJUQ\n",
       "4    ETWR1EHV\n",
       "Name: filename, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_filenames = test_data_df[\"filename\"]\n",
    "test_data_filenames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_ch1 = test_data_df[\"ch1\"]\n",
    "test_data_ch2 = test_data_df[\"ch2\"]\n",
    "test_data_ch3 = test_data_df[\"ch3\"]\n",
    "test_data_ch4 = test_data_df[\"ch4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight initialization helper function\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return(tf.Variable(init_random_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias initialization function\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1,  shape=shape)\n",
    "    return (tf.Variable(init_bias_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d convolutional layer\n",
    "def conv2d(x, W):\n",
    "    return (tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=\"SAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max pool layer\n",
    "def max_pool_2by2(x):\n",
    "    return (tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return (tf.nn.relu(conv2d(input_x, W)+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return (tf.nn.relu(tf.matmul(input_layer, W)+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return (tf.matmul(input_layer, W)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Inputs\"):\n",
    "    # getting images\n",
    "    ch1_input = tf.placeholder(tf.float32, shape=[None, 50, 200, 3], name=\"ch1_input\")\n",
    "    ch2_input = tf.placeholder(tf.float32, shape=[None, 50, 200, 3], name=\"ch2_input\")\n",
    "    ch3_input = tf.placeholder(tf.float32, shape=[None, 50, 200, 3], name=\"ch3_input\")\n",
    "    ch4_input = tf.placeholder(tf.float32, shape=[None, 50, 200, 3], name=\"ch4_input\")\n",
    "    # gettin the one hot labels\n",
    "    y_true = tf.placeholder(tf.float32, shape=[None, 2], name=\"labels\")\n",
    "    # getting hold probability value\n",
    "    hold_prob = tf.placeholder(tf.float32, name=\"hold_probability\")\n",
    "    # batch size\n",
    "    batch_size = tf.placeholder(tf.int64, name=\"batch_size\")\n",
    "    # number of parallel calls for dataset map\n",
    "    num_par_calls = tf.placeholder(tf.int32, name=\"num_par_calls\")\n",
    "    # learning rate\n",
    "    learning_rate = tf.placeholder(tf.float32, name=\"learning_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### image parsing fn\n",
    "def _image_parse_fn(label, ch1, ch2, ch3, ch4):\n",
    "    # reading file\n",
    "    ch1_img = tf.read_file(ch1)\n",
    "    ch2_img = tf.read_file(ch2)\n",
    "    ch3_img = tf.read_file(ch3)\n",
    "    ch4_img = tf.read_file(ch4)\n",
    "    # image decoding\n",
    "    ch1_img_decoded = tf.image.decode_png(ch1_img)\n",
    "    ch2_img_decoded = tf.image.decode_png(ch2_img)\n",
    "    ch3_img_decoded = tf.image.decode_png(ch3_img)\n",
    "    ch4_img_decoded = tf.image.decode_png(ch4_img)\n",
    "    # image cropping\n",
    "    ch1_img_resized = tf.image.crop_to_bounding_box(ch1_img_decoded, 463, 0, 50, 800)\n",
    "    ch2_img_resized = tf.image.crop_to_bounding_box(ch2_img_decoded, 463, 0, 50, 800)\n",
    "    ch3_img_resized = tf.image.crop_to_bounding_box(ch3_img_decoded, 463, 0, 50, 800)\n",
    "    ch4_img_resized = tf.image.crop_to_bounding_box(ch4_img_decoded, 463, 0, 50, 800)\n",
    "    # resize images\n",
    "    ch1_img_resized = tf.image.resize_images(ch1_img_resized, [50, 200])\n",
    "    ch2_img_resized = tf.image.resize_images(ch2_img_resized, [50, 200])\n",
    "    ch3_img_resized = tf.image.resize_images(ch3_img_resized, [50, 200])\n",
    "    ch4_img_resized = tf.image.resize_images(ch4_img_resized, [50, 200])\n",
    "    # normalize images\n",
    "    ch1_img_normalized = tf.div(ch1_img_resized, 255)\n",
    "    ch2_img_normalized = tf.div(ch2_img_resized, 255)\n",
    "    ch3_img_normalized = tf.div(ch3_img_resized, 255)\n",
    "    ch4_img_normalized = tf.div(ch4_img_resized, 255)\n",
    "    return (label, ch1_img_normalized, ch2_img_normalized, ch3_img_normalized, ch4_img_normalized)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Datasets\n",
    "with tf.name_scope(\"Datasets\"):\n",
    "    # Train Datasets\n",
    "    with tf.name_scope(\"Train_Dataset\"):\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_data_labels,\n",
    "                                                           train_data_ch1,\n",
    "                                                           train_data_ch2,\n",
    "                                                           train_data_ch3,\n",
    "                                                           train_data_ch4))\n",
    "        train_dataset = train_dataset.shuffle(10000)\n",
    "        train_dataset = train_dataset.repeat()\n",
    "        train_dataset = train_dataset.map(_image_parse_fn, num_parallel_calls=num_par_calls)\n",
    "        train_dataset = train_dataset.batch(batch_size)\n",
    "    \n",
    "    # train evaluation dataset    \n",
    "    with tf.name_scope(\"eval_train_dataset\"):\n",
    "        eval_train_dataset = tf.data.Dataset.from_tensor_slices((train_data_labels,\n",
    "                                                           train_data_ch1,\n",
    "                                                           train_data_ch2,\n",
    "                                                           train_data_ch3,\n",
    "                                                           train_data_ch4))\n",
    "        eval_train_dataset = eval_train_dataset.map(_image_parse_fn, num_parallel_calls=num_par_calls)\n",
    "        eval_train_dataset = eval_train_dataset.batch(batch_size)\n",
    "    \n",
    "    # Validation dataset with only one epoch and no shuffle\n",
    "    with tf.name_scope(\"validation_dataset\"):\n",
    "        validation_dataset = tf.data.Dataset.from_tensor_slices((validation_data_labels,\n",
    "                                                           validation_data_ch1,\n",
    "                                                           validation_data_ch2,\n",
    "                                                           validation_data_ch3,\n",
    "                                                           validation_data_ch4))\n",
    "        validation_dataset = validation_dataset.map(_image_parse_fn, num_parallel_calls=num_par_calls)\n",
    "        validation_dataset = validation_dataset.batch(batch_size)\n",
    "    \n",
    "    # test dataset with only one epoch and no shuffle\n",
    "    with tf.name_scope(\"test_dataset\"):\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((test_data_filenames,\n",
    "                                                           test_data_ch1,\n",
    "                                                           test_data_ch2,\n",
    "                                                           test_data_ch3,\n",
    "                                                           test_data_ch4))\n",
    "        test_dataset = test_dataset.map(_image_parse_fn, num_parallel_calls=num_par_calls)\n",
    "        test_dataset = test_dataset.batch(batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Iterator\"):\n",
    "    # train iterator\n",
    "    with tf.name_scope(\"Train_Iterator\"):\n",
    "        train_iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "        next_element_train = train_iterator.get_next()\n",
    "        train_init_op = train_iterator.make_initializer(train_dataset)\n",
    "    # train evaluation iterator\n",
    "    with tf.name_scope(\"train_evaluation_iterator\"):\n",
    "        eval_train_iterator = tf.data.Iterator.from_structure(eval_train_dataset.output_types, eval_train_dataset.output_shapes)\n",
    "        next_element_eval_train = eval_train_iterator.get_next()\n",
    "        eval_train_init_op = eval_train_iterator.make_initializer(eval_train_dataset)\n",
    "    # validation iterator\n",
    "    with tf.name_scope(\"validation_iterator\"):\n",
    "        validation_iterator = tf.data.Iterator.from_structure(validation_dataset.output_types, validation_dataset.output_shapes)\n",
    "        next_element_validation = validation_iterator.get_next()\n",
    "        validation_init_op = validation_iterator.make_initializer(validation_dataset)\n",
    "    # test iterator\n",
    "    with tf.name_scope(\"test_iterator\"):\n",
    "        test_iterator = tf.data.Iterator.from_structure(test_dataset.output_types, test_dataset.output_shapes)\n",
    "        next_element_test = test_iterator.get_next()\n",
    "        test_init_op = test_iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"input_manipulation\"):\n",
    "    concat_input = tf.concat([ch1_input, ch2_input, ch3_input, ch4_input], 3, name=\"Image_concat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Block - Convolutional and maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"First_cnn_block\"):\n",
    "    convo_1 = convolutional_layer(concat_input, shape=[5, 3, 12, 128])\n",
    "    maxpool_1 = max_pool_2by2(convo_1)\n",
    "    dropout_1 = tf.nn.dropout(maxpool_1, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Block - Convolutional and maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Second_cnn_block\"):\n",
    "    convo_2 = convolutional_layer(dropout_1, shape=[5, 3, 128, 256])\n",
    "    maxpool_2 = max_pool_2by2(convo_2)\n",
    "    dropout_2 = tf.nn.dropout(maxpool_2, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Block - 2 Convolutionals and maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Third_cnn_block\"):\n",
    "    convo_3 = convolutional_layer(dropout_2, shape=[3, 3, 256, 384])\n",
    "    convo_4 = convolutional_layer(convo_3, shape=[3, 3, 384, 384])\n",
    "    maxpool_3 = max_pool_2by2(convo_4)\n",
    "    dropout_3 = tf.nn.dropout(maxpool_3, keep_prob=hold_prob)\n",
    "# output shape: [None, 7, 25,384]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth block - 2 Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Dense_layers_block\"):\n",
    "    flatten_1 = tf.reshape(dropout_3, [-1, 7*25*384])\n",
    "    dense_layer_1 = normal_full_layer(flatten_1, 256)\n",
    "    dense_layer_2 = normal_full_layer(dense_layer_1, 128)\n",
    "    dropout_4 = tf.nn.dropout(dense_layer_2, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Output_layer\"):\n",
    "    y_pred = output_full_layer(dropout_4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Loss\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=y_pred)\n",
    "    mean_cross_entropy = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"training\"):\n",
    "    train = optimizer.minimize(mean_cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Predicting\"):\n",
    "    y_soft = tf.nn.softmax(y_pred)\n",
    "    prediction = tf.argmax(y_soft, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalution Metrics - Accuracy, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "with tf.name_scope(\"Accuracy_tensorboard\"):\n",
    "    y_true_arg_max = tf.argmax(y_true, axis=1)\n",
    "    correct_predictions = tf.equal(prediction, y_true_arg_max)\n",
    "    batch_acc = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    acc_arr = tf.placeholder(tf.float32)\n",
    "    full_accuracy = tf.reduce_mean(acc_arr)\n",
    "    accuracy_summary = tf.summary.scalar(\"Accuracy\", full_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "with tf.name_scope(\"Loss_tensorboard\"):\n",
    "    loss_arr = tf.placeholder(tf.float32)\n",
    "    full_loss = tf.reduce_mean(loss_arr)\n",
    "    loss_summary = tf.summary.scalar(\"Loss\", full_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary merger\n",
    "merged_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/final.ckpy\n",
      "Saved train summary at step #5400\n",
      "Saved validation summary at step #5400\n",
      "Saved train summary at step #5500\n",
      "Saved validation summary at step #5500\n",
      "Saved checkpoint in step #5500\n",
      "Saved train summary at step #5600\n",
      "Saved validation summary at step #5600\n",
      "Saved train summary at step #5700\n",
      "Saved validation summary at step #5700\n",
      "Saved train summary at step #5800\n",
      "Saved validation summary at step #5800\n",
      "Saved train summary at step #5900\n",
      "Saved validation summary at step #5900\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-c769fd06f317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mfine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ch1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ch2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ch3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ch4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mfine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size_input = 32\n",
    "number_of_par_calls = 4\n",
    "learning_rate_input = 0.001\n",
    "dropout_input = 0.7\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    # initiate variables\n",
    "    #sess.run(init)\n",
    "    \n",
    "    \n",
    "    saver.restore(sess, \"./model/final.ckpy\")\n",
    "    \n",
    "    # create filewriters for tensorboard\n",
    "    train_writer = tf.summary.FileWriter(\"./tensorboard/train_run2\", graph=tf.get_default_graph())\n",
    "    validation_writer = tf.summary.FileWriter(\"./tensorboard/validation_run2\", graph=tf.get_default_graph())\n",
    "    \n",
    "    # initiate training iterator\n",
    "    dataset_feed = {batch_size:batch_size_input, num_par_calls:number_of_par_calls}\n",
    "    sess.run(train_init_op, feed_dict=dataset_feed)\n",
    "    \n",
    "    # training\n",
    "    for step in range(5301, 10001):\n",
    "        fine = 1\n",
    "        # saving summary every one hundred steps\n",
    "        if step % 100 == 0:\n",
    "            # Evaluate training data metrics\n",
    "            acc = []\n",
    "            loss = []\n",
    "            sess.run(eval_train_init_op, feed_dict=dataset_feed)\n",
    "            # run one epoch on training evaluation dataset\n",
    "            for i in range(35):\n",
    "                fine = 1\n",
    "                try:\n",
    "                    batch_labels, batch_ch1, batch_ch2, batch_ch3, batch_ch4 = sess.run(next_element_eval_train)\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "                except tf.errors.InvalidArgumentError:\n",
    "                    fine = 0\n",
    "                if (fine == 1):\n",
    "                    train_eval_feed = {y_true:batch_labels, ch1_input:batch_ch1, ch2_input:batch_ch2,\n",
    "                        ch3_input:batch_ch3, ch4_input:batch_ch4, hold_prob:1.0}\n",
    "                    acc.append(sess.run(batch_acc, feed_dict=train_eval_feed))\n",
    "                    loss.append(sess.run(mean_cross_entropy, feed_dict=train_eval_feed))\n",
    "                fine = 1\n",
    "            train_eval_feed = {acc_arr: acc, loss_arr:loss}\n",
    "            # save the summary\n",
    "            summary = sess.run(merged_op, feed_dict=train_eval_feed)\n",
    "            train_writer.add_summary(summary, step)\n",
    "            train_writer.flush()\n",
    "            print(\"Saved train summary at step #{}\".format(step))\n",
    "            \n",
    "            # Evaluate validation data metrics\n",
    "            acc = []\n",
    "            loss = []\n",
    "            sess.run(validation_init_op, feed_dict=dataset_feed)\n",
    "            while True:\n",
    "                fine = 1\n",
    "                try:\n",
    "                    batch_labels, batch_ch1, batch_ch2, batch_ch3, batch_ch4 = sess.run(next_element_validation)\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "                except tf.errors.InvalidArgumentError:\n",
    "                    fine = 0\n",
    "                if (fine == 1):\n",
    "                    validation_feed = {y_true:batch_labels, ch1_input:batch_ch1, ch2_input:batch_ch2,\n",
    "                      ch3_input:batch_ch3, ch4_input:batch_ch4, hold_prob:1.0}\n",
    "                    acc.append(sess.run(batch_acc, feed_dict=validation_feed))\n",
    "                    loss.append(sess.run(mean_cross_entropy, feed_dict=validation_feed))\n",
    "                fine = 1\n",
    "            validation_feed = {acc_arr: acc, loss_arr:loss}\n",
    "            summary = sess.run(merged_op, feed_dict=validation_feed)\n",
    "            validation_writer.add_summary(summary, step)\n",
    "            validation_writer.flush()\n",
    "            print(\"Saved validation summary at step #{}\".format(step))\n",
    "        \n",
    "        # Checkpoint saving every 1000 steps\n",
    "        if step % 500 == 0:\n",
    "            saver.save(sess, \"./model/step_{}.ckpy\".format(step))\n",
    "            print(\"Saved checkpoint in step #{}\".format(step))\n",
    "        \n",
    "        # training\n",
    "        fine = 1\n",
    "        try:\n",
    "            batch_labels, batch_ch1, batch_ch2, batch_ch3, batch_ch4 = sess.run(next_element_train)\n",
    "        except tf.errors.InvalidArgumentError:\n",
    "            fine = 0\n",
    "        if (fine == 1):\n",
    "            train_feed = {y_true:batch_labels, ch1_input:batch_ch1, ch2_input:batch_ch2,\n",
    "                      ch3_input:batch_ch3, ch4_input:batch_ch4, hold_prob:dropout_input,\n",
    "                      learning_rate:learning_rate_input}\n",
    "            sess.run(train, feed_dict=train_feed)\n",
    "        if step == 0:\n",
    "            print(\"Finished first train call\")\n",
    "    \n",
    "    saver.save(sess, \"./model/final10k.ckpy\")\n",
    "    print(\"Training is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_input = 1\n",
    "number_of_par_calls = 2\n",
    "learning_rate_input = 0.001\n",
    "dropout_input = 1.0\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    # initiate variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    #saver.restore(sess, \"./best_models/eightyfouracc/final.ckpy\")\n",
    "    \n",
    "    # create filewriters for tensorboard\n",
    "    train_writer = tf.summary.FileWriter(\"./tensorboard/train_run2\", graph=tf.get_default_graph())\n",
    "    validation_writer = tf.summary.FileWriter(\"./tensorboard/validation_run2\", graph=tf.get_default_graph())\n",
    "    \n",
    "    # initiate training iterator\n",
    "    dataset_feed = {batch_size:batch_size_input, num_par_calls:number_of_par_calls}\n",
    "    sess.run(train_init_op, feed_dict=dataset_feed)\n",
    "    sess.run(validation_init_op, feed_dict=dataset_feed)\n",
    "            # run one epoch on training evaluation dataset\n",
    "    while True:\n",
    "        try:\n",
    "            batch_labels, batch_ch1, batch_ch2, batch_ch3, batch_ch4 = sess.run(next_element_validation)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "        except tf.errors.InvalidArgumentError:\n",
    "            print(batch_labels)\n",
    "        train_eval_feed = {y_true:batch_labels, ch1_input:batch_ch1, ch2_input:batch_ch2,\n",
    "            ch3_input:batch_ch3, ch4_input:batch_ch4, hold_prob:1.0}\n",
    "#     train_feed = {y_true:batch_labels, ch1_input:batch_ch1, ch2_input:batch_ch2,\n",
    "#                   ch3_input:batch_ch3, ch4_input:batch_ch4, hold_prob:dropout_input,\n",
    "#                   learning_rate:learning_rate_input}\n",
    "#     res = sess.run(dropout_3, feed_dict=train_feed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/final.ckpy\n",
      "Number: 1\n",
      "Number: 2\n",
      "Number: 3\n",
      "Number: 4\n",
      "Number: 5\n",
      "Number: 6\n",
      "Number: 7\n",
      "Number: 8\n",
      "Number: 9\n",
      "Number: 10\n",
      "Number: 11\n",
      "Number: 12\n",
      "Number: 13\n",
      "Number: 14\n",
      "Number: 15\n",
      "Number: 16\n",
      "Number: 17\n",
      "Number: 18\n",
      "Number: 19\n",
      "Number: 20\n",
      "Number: 21\n",
      "Number: 22\n",
      "Number: 23\n",
      "Number: 24\n",
      "Number: 25\n",
      "Number: 26\n",
      "Number: 27\n",
      "Number: 28\n",
      "Number: 29\n",
      "Number: 30\n",
      "Number: 31\n",
      "Number: 32\n"
     ]
    }
   ],
   "source": [
    "batch_size_input = 32\n",
    "number_of_par_calls = 4\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    saver.restore(sess, \"./model/final.ckpy\")\n",
    "    \n",
    "    dataset_feed = {batch_size:batch_size_input, num_par_calls:number_of_par_calls}\n",
    "    sess.run(test_init_op, feed_dict=dataset_feed)\n",
    "    results = {\"filename\":[], \"label\":[]}\n",
    "    acc = []\n",
    "    loss = []\n",
    "    i = 1\n",
    "    while True:\n",
    "        try:\n",
    "            filenames, batch_ch1, batch_ch2, batch_ch3, batch_ch4 = sess.run(next_element_test)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "        test_feed = {ch1_input:batch_ch1, ch2_input:batch_ch2,\n",
    "                  ch3_input:batch_ch3, ch4_input:batch_ch4, hold_prob:1.0}\n",
    "        result = sess.run(prediction, feed_dict=test_feed)\n",
    "        for file in filenames:\n",
    "            results[\"filename\"].append(file.decode())\n",
    "        for res in result:\n",
    "            results[\"label\"].append(res + 1)\n",
    "        print(\"Number: {}\".format(i))\n",
    "        i += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y3K7JETF</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W6HOIV84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UT7X0FXK</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396IEJUQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ETWR1EHV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename  label\n",
       "0  Y3K7JETF      2\n",
       "1  W6HOIV84      1\n",
       "2  UT7X0FXK      2\n",
       "3  396IEJUQ      1\n",
       "4  ETWR1EHV      1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = pd.DataFrame(results)\n",
    "final_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.set_index(\"filename\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    535\n",
       "1    467\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv(\"~/results_subvocal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final accuracy: {}\\tFinal Loss: {}\".format(final_test_accuracy, final_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = tf.data.Dataset.from_tensor_slices((final_filenames,\n",
    "                                                    final_ch1,\n",
    "                                                    final_ch2,\n",
    "                                                    final_ch3,\n",
    "                                                    final_ch4))\n",
    "final_dataset = final_dataset.map(_image_parse_fn, num_parallel_calls=num_par_calls)\n",
    "final_dataset = final_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_iterator = tf.data.Iterator.from_structure(test_dataset.output_types, test_dataset.output_shapes)\n",
    "next_element_final = final_iterator.get_next()\n",
    "final_init_op = final_iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
